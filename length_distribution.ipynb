{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rich\n",
    "from tqdm import tqdm\n",
    "\n",
    "import datagen\n",
    "import our_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['349_6_6.json', '80_3_6.json', '80_3_6.json.pkl', '349_6_6.json.pkl']\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path.cwd() / \"data\" \n",
    "names = [x.name for x in DATA_DIR.iterdir()]\n",
    "names.sort(key=lambda x: x.rsplit(\".\", 1)[-1])\n",
    "print(names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = \"349_6_6.json.pkl\"\n",
    "assert FILE_NAME in names, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_sorted(l):\n",
    "    return all(l[i] <= l[i + 1] for i in range(len(l) - 1))\n",
    "\n",
    "def plot_lengths(lengths, x_subdiv=1, verbose=False):\n",
    "    if verbose:\n",
    "        print(\"Checking if lengths are sorted...\")\n",
    "    assert is_sorted(lengths)\n",
    "    if verbose:\n",
    "        print(\"Plotting...\")\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.xticks(np.arange(int(np.ceil((np.max(lengths) + 1) / x_subdiv))) * x_subdiv)\n",
    "    plt.yticks(np.linspace(0, 1, 21))\n",
    "    plt.plot(lengths, np.linspace(0, 1, len(lengths)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">Loading data file.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mLoading data file.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">Loading PKL data file </span><span style=\"color: #000080; text-decoration-color: #000080\">\"/home/mila/g/gagnonju/SelfLearnedExplanations/data/349_6_6.json.pkl\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mLoading PKL data file \u001b[0m\u001b[34m\"/home/mila/g/gagnonju/SelfLearnedExplanations/data/349_6_6.json.pkl\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">Done loading file.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mDone loading file.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([1, 2, 3, 4, 5, 6])\n",
      "dict_keys([1, 2, 3, 4, 5, 6])\n",
      "Building nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 148069.10it/s]<?, ?it/s]\n",
      "100%|██████████| 200000/200000 [00:03<00:00, 64708.11it/s]\n",
      "100%|██████████| 200000/200000 [01:16<00:00, 2625.99it/s] 6,  1.55s/it]\n",
      "100%|██████████| 200000/200000 [00:12<00:00, 16027.50it/s]7, 32.64s/it]\n",
      "100%|██████████| 200000/200000 [01:44<00:00, 1918.32it/s]50, 25.12s/it]\n",
      "100%|██████████| 200000/200000 [02:06<00:00, 1576.40it/s]52, 52.64s/it]\n",
      "Building nodes for train: 100%|██████████| 6/6 [05:22<00:00, 53.81s/it]\n",
      "100%|██████████| 300/300 [00:00<00:00, 158096.65it/s]?, ?it/s]\n",
      "100%|██████████| 200000/200000 [00:03<00:00, 66190.73it/s]\n",
      "100%|██████████| 200000/200000 [00:06<00:00, 30416.42it/s],  1.51s/it]\n",
      "100%|██████████| 200000/200000 [00:12<00:00, 16299.55it/s],  3.62s/it]\n",
      "100%|██████████| 200000/200000 [02:23<00:00, 1397.80it/s]3,  6.85s/it]\n",
      "100%|██████████| 200000/200000 [00:30<00:00, 6552.25it/s]4, 54.22s/it]\n",
      "Building nodes for eval: 100%|██████████| 6/6 [03:15<00:00, 32.58s/it]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = our_tokenizer.ArithmeticTokenizer()\n",
    "data, config = datagen.load_dataset(None, DATA_DIR / FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">train - Num points:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mtrain - Num points:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain - < 1 >: 300\n",
      "\ttrain - < 2 >: 200000\n",
      "\ttrain - < 3 >: 200000\n",
      "\ttrain - < 4 >: 200000\n",
      "\ttrain - < 5 >: 200000\n",
      "\ttrain - < 6 >: 200000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">eval - Num points:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34meval - Num points:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\teval - < 1 >: 300\n",
      "\teval - < 2 >: 200000\n",
      "\teval - < 3 >: 200000\n",
      "\teval - < 4 >: 200000\n",
      "\teval - < 5 >: 200000\n",
      "\teval - < 6 >: 200000\n",
      "< 1 > value lens percentiles:\n",
      "\t85.0%: 2\n",
      "\t90.0%: 2\n",
      "\t95.0%: 3\n",
      "\t99.0%: 5\n",
      "< 1 > oracle lens percentiles :\n",
      "\t85.0%: 8\n",
      "\t90.0%: 8\n",
      "\t95.0%: 8\n",
      "\t99.0%: 8\n",
      "By value and by oracle length: (value = 5, oracle = 8)\n",
      "\t< 1 > count: 600 / 600 100.00%\n",
      "By value only: 5\n",
      "\t< 1 > count: 600 / 600 100.00%\n",
      "By oracle only: 8\n",
      "\t< 1 > count: 600 / 600 100.00%\n"
     ]
    }
   ],
   "source": [
    "for split, levels in data.items():\n",
    "    rich.print(f\"[bold blue]{split} - Num points:\")\n",
    "    for name, level in levels.items():\n",
    "        print(f\"\\t{split} - < {name} >: {len(level)}\")\n",
    "\n",
    "\n",
    "levels = collections.defaultdict(list)\n",
    "\n",
    "for split, levels_per_split in data.items():\n",
    "    for level, level_data in levels_per_split.items():\n",
    "        levels[level].extend(level_data)\n",
    "\n",
    "\n",
    "def filter_by_total_length(nodes, limit):\n",
    "    good_nodes = []\n",
    "    for node in nodes:\n",
    "        if not len(tokenizer(node.get_oracle_str()[0], return_tensors=None, no_eos=True)) <= limit:\n",
    "            continue\n",
    "        good_nodes.append(node)\n",
    "    return good_nodes\n",
    "\n",
    "def filter_by_value_length(nodes, limit):\n",
    "    output = []\n",
    "    for node in nodes:\n",
    "        if not all(len(tokenizer(v.get_value(), return_tensors=None, no_eos=True)) <= limit for v in datagen.get_all_desc(node)):\n",
    "            continue\n",
    "        output.append(node)\n",
    "    return output\n",
    "\n",
    "\n",
    "value_lens = {}\n",
    "oracle_lens = {}\n",
    "percentiles = [.85, .9, .95, .99]\n",
    "BY_VALUE_QUANTILE = 99\n",
    "BY_ORACLE_QUANTILE = 95\n",
    "\n",
    "for level, root_nodes in levels.items():\n",
    "    all_nodes = list(datagen.multiple_get_all_desc(level_data))\n",
    "    value_lens[level] = [len(tokenizer(v.get_value(), return_tensors=None, no_eos=True)) for v in all_nodes]\n",
    "    value_lens[level].sort()\n",
    "    oracle_lens[level] = [len(tokenizer(node.get_oracle_str()[0], return_tensors=None, no_eos=True)) for node in root_nodes]\n",
    "    oracle_lens[level].sort()\n",
    "    print(f\"< {level} > value lens percentiles:\")\n",
    "    for p in percentiles:\n",
    "        print(f\"\\t{p * 100}%: {int(np.percentile(value_lens[level], p * 100))}\")\n",
    "    print(f\"< {level} > oracle lens percentiles :\")\n",
    "    for p in percentiles:\n",
    "        print(f\"\\t{p * 100}%: {int(np.percentile(oracle_lens[level], p * 100))}\")\n",
    "\n",
    "\n",
    "    # By value and by oracle length``\n",
    "    \n",
    "    value_limit = math.ceil(np.percentile(value_lens[level], BY_VALUE_QUANTILE))\n",
    "    oracle_limit = math.ceil(np.percentile(oracle_lens[level], BY_ORACLE_QUANTILE))\n",
    "    \n",
    "    by_oracle_length = filter_by_total_length(root_nodes, oracle_limit)\n",
    "    doubly_filtered = filter_by_value_length(by_oracle_length, value_limit)\n",
    "    print(f\"By value and by oracle length: (value = {value_limit}, oracle = {oracle_limit})\")\n",
    "    print(f\"\\t< {level} > count: {len(doubly_filtered)} / {len(root_nodes)} {len(doubly_filtered)/len(root_nodes):0.2%}\")\n",
    "\n",
    "    by_value_length = filter_by_value_length(root_nodes, value_limit)\n",
    "    print(f\"By value only: {value_limit}\")\n",
    "    print(f\"\\t< {level} > count: {len(by_value_length)} / {len(root_nodes)} {len(by_value_length)/len(root_nodes):0.2%}\")\n",
    "\n",
    "    print(f\"By oracle only: {oracle_limit}\")\n",
    "    print(f\"\\t< {level} > count: {len(by_oracle_length)} / {len(root_nodes)} {len(by_oracle_length)/len(root_nodes):0.2%}\")\n",
    "\n",
    "\n",
    "assert False\n",
    "\n",
    "for name, level_data in levels.items():\n",
    "    assert isinstance(name, (int, str))\n",
    "    rich.print(f\"[bold blue]Level < {name} >:\")\n",
    "    plot_lengths(value_lens)\n",
    "    plot_lengths(oracle_lens, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "46daadc73974f0324ecc1592e5131128499dc93a3a1cbadf14a4773500af3ac4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
